[project]
name = "gremory"
version = "0.1.0"
description = "Lightweight LLM Inference Server"
readme = "README.md"
requires-python = ">=3.11,<3.12"
dependencies = [
    "litserve>=0.2.2",
    "llama-cpp-python>=0.2.90; platform_system != 'Windows'",
    "llama-cpp-python==0.2.90; platform_system == 'Windows'",
    "transformers>=4.44.2",
    "uvloop>=0.20.0; platform_system != 'Windows'",
    "winloop>=0.1.6; platform_system == 'Windows'",
    "python-dotenv>=1.0.1",
    "light-the-torch>=0.7.5",
    "flask-cloudflared>=0.0.14",
    "pydantic-settings>=2.5.2",
    "openai>=1.47.0",
]

[tool.uv]
package = true

[tool.uv.sources]
llama-cpp-python = {url = "https://github.com/abetlen/llama-cpp-python/releases/download/v0.2.90-cu121/llama_cpp_python-0.2.90-cp311-cp311-win_amd64.whl"}
